     VILNIUS UNIVERSITY
KAUNAS FACULTY
     INSTITUTE OF SOCIAL SCIENCES AND APPLIED INFORMATICS
      Study programme Information Systems and Cyber Security 
      State code 6121BX003
     SHUBHAM BHASKER
      BACHELOR'S THESIS
     LINUX FORM SCRATCH - LFS 
     VILNIUS UNIVERSITY
KAUNAS FACULTY
     INSTITUTE OF SOCIAL SCIENCES AND APPLIED INFORMATICS
     SHUBHAM BHASKER
      BACHELOR'S THESIS
     LINUX FROM SCRATCH - LFS
        Allowed to defend                                Bachelor student                                                                    (signature)                                            Scientific advisor                                                                    (signature)                                                                                                                    (scientific degree of the advisor, scientific pedagogical name, name and surname)                                            Thesis submitted on                                                        Registration No:                  
Contents
         LIST OF ABBREVIATIONS	8
         SUMMARY	10
         SANTRAUKA	11
         INTRODUCTION	12
         1.	ANALYTICAL PART	16
         1.1 Problem Area Characteristics	16
         1.1.1 Linux From Scratch Build Process Overview	16
         1.1.2 Educational Context and learning objectives	17
         1.1.3 External Environment and Technological Trends	18
         1.1.4 Current Challenges and User Pain Points	19
         1.1.5 Business and Educational Value Proposition	20
         1.2 Local LFS Build Architecture and Wizard Automation	21
         1.2.1 Paradigm 1: The Fragility of the Manual LFS Build Flow	21
         1.2.2 The Architectural Limits of Legacy Automation (ALFS/jhalfs)	22
         1.2.3 Proposed System: Local-First Philosophy and Architecture	23
         1.2.4 The Two-Pass Build Rationale: GCC Bootstrapping for Verification	23
         1.3 Isolation Models, Performance, and the PoC Justification	24
         1.3.1 Comparative Analysis of Isolation Mechanisms	24
         1.3.2 Justification of the Hybrid WSL Architecture	25
         1.4 Analysis of Current Information Flow	26
         1.4.1 Legacy Information Flow (Manual LFS)	26
         1.4.2 Proposed Information Flow (Automated and Scripted PoC)	27
         1.4.3 Identification of Key Issues to Resolve	28
         1.4.4 Synthesis of Analytical Findings and Technical Justification (Local Project)	28
         2 TECHNICAL TASK	30
         3 PROJECT PART	33
         3.1 Project Aim and Architectural Justification	33
         3.1.1 Functional Requirements	33
         3.2.2 Non-Functional Requirements	35
         3.1.3 Restatement of Project Aim and Objectives	36
         3.1.4 Architectural Rationale: Justification of the Hybrid WSL/chroot Proof-of-Concept (PoC)	37
         3.2 Logical Structure of the Automated Build System	38
         3.2.1 Hierarchy of Computerized Functions (HCIS)	38
         3.2.2 Conceptual Data Model and Entity Relationships (CDM)	40
         3.2.3 System Dynamics and Build State Diagram	43
         3.2.4 Formal Description of LFS Build Procedures and Optimization	45
         3.2.5 Formal Calculation: Performance Optimization via Amdahl's Law	46
         3.3 Information Architecture and Data Specification	47
         3.3.1 LFS Path Isolation	47
         3.3.2 Target Triplet	47
         3.4 Database Project (Detailed Entity Schemas)	47
         3.4.1 Detailed Build Job Entity Schema (Conceptual Data Model)	48
         3.4.2 Output Data Specification and Artifact Management	48
         3.4.3 Software Architecture and Execution Environment	51
         3.4.4 Toolchain Management and Dependency Closure	52
         3.5 Logical UI Component Structure	54
         3.5.1 Build Submission Wizard	54
         3.5.2 Real-time Monitoring Dashboard	55
         3.5.3 Structured Log Viewer Module	57
         3.5.4 Project Installation and Deployment Timetable	58
         4 PART OF SOFTWARE IMPLEMENTATION	59
         4.1 Physical Database Specification (DDL)	59
         4.1.1 Physical Schema for LFS_Builds Entity	59
         4.1.2 Sample Build Record Instantiation (Example Database Record)	60
         4.2 Formal Module Specifications	61
         4.2.1 Module Specification: init-lfs-env.sh (Environment Setup)	61
         4.2.2 Module Specification: build-lfs-complete-local.sh (Pass 1 Orchestrator)	62
         4.2.3 Module Specification: chroot-and-build.sh (Isolation Transition and Kernel Binding)	63
         4.2.4 Module Specification: BUILD-LFS-CORRECT.ps1 (Host API Gateway)	63
         4.3 Programmer's Guide: System Architecture and Maintenance	64
         4.3.1 Toolchain Integrity	65
         4.3.2 Stability and Recovery	66
         4.3.3 Detailed User Guide: Operational Procedures	66
         4.3.4 System Testing Results and Evaluation	67
         5 CONCLUSIONS	69
         5.1 Novelty and Distinction from Existing Solutions	70
         
         
      


      
      Table 1: Key Issues to Resolve	24
         Table 2: Analytical Findings and Technical Justification	25
         Table 3: Functional Requirements	30
         Table 4 Non-Functional Requirements	32
         Table 5: Build Job Entity Schema (Conceptual Data Model)	44
         Table 6: Database Schema	46
         Table 7: Logical UI Component Breakdown and Data Mapping	53
         Table 8: Installation and Deployment Timetable	54
         Table 9 : Physical Database Schema (LFS_Builds Table)	56
         Table 10: Sample Build Database	56
         Table 11: Module Execution	57
         Table 12: Hybrid WSL/chroot Isolation	60
         Table 13: Toolchain Integrity - Two-Pass Bootstrapping Audit	61
         Table 14: Toolchain Integrity Verification Test Matrix Results	63
         Table 15: Performance and Resource Utilization Assessment	64
         Table 16: Comparative Evaluation Against Legacy Solutions	64



      Table 1: Key Issues to Resolve	25
         Table 2: Analytical Findings and Technical Justification	26
         Table 3: Functional Requirements	31
         Table 4 Non-Functional Requirements	33
         Table 5: Build Job Entity Schema (Conceptual Data Model)	45
         Table 6: Database Schema	47
         Table 7: Logical UI Component Breakdown and Data Mapping	54
         Table 8: Installation and Deployment Timetable	55
         Table 9 : Physical Database Schema (LFS_Builds Table)	57
         Table 10: Sample Build Database	57
         Table 11: Module Execution	58
         Table 12: Hybrid WSL/chroot Isolation	61
         Table 13: Toolchain Integrity - Two-Pass Bootstrapping Audit	62
         Table 14: Toolchain Integrity Verification Test Matrix Results	64
         Table 15: Performance and Resource Utilization Assessment	65
         Table 16: Comparative Evaluation Against Legacy Solutions	65

      
      
      



LIST OF ABBREVIATIONS
      API - Application Programming Interface
      AI - Artificial Intelligence
      CDM - Conceptual Data Model
      CI/CD - Continuous Integration/ Continuous Development
      CLI - Command Line Interface
      CRUD - Create, Read, Update, Delete
      DB - Database
      DBMS - Database Management System
      DDL - Data Definition Language
      ECS - Elastic Common Schema
      FN - Functional Requirement
      GCS - Google Cloud Storage
      GRUB - Grand Unified Bootloader
      GUI - Graphical User Interface
      HCIS - Hierarchy of Computerized Functions
      IoT - Internet of Things
      ISO - International Organization for Standardization
      ISCS - Information Systems and Cyber Security
      ISOLINUX - A boot loader for Linux that operates from a CD/DVD or USB drive
      JWT - JSON web tokens
      LFS - Linux from scratch
      LFS_TGT - Linux From Scratch Target
      NFN - Non- Functional Requirement
      OS - Operating System
      PoC - Proof-of-Concept
      RAM - Random Access Memory
      RLS - Row level security
      TCB - Trusted Computing Base
      UI - User interface
      WSL - Windows Subsystem for Linux
      


         Bhasker Shubham, (2025), Linux From Scratch - LFS.
         Bachelor's Thesis. Kaunas: Vilnius University Kaunas Faculty, [57] pages
         
SUMMARY
         This thesis creates and tests an automated framework for building Linux From Scratch (LFS) that focuses on making the manual compilation process less fragile, time-consuming, and error-prone.  The work solves some of the main problems with the LFS methodology, such as host dependency, lack of reproducibility, operational fragility, and the steep learning curve. It does this by using a hybrid automation architecture that combines PowerShell-based orchestration, WSL execution, and chroot-based isolation. 
         
          The analytical part looks at the flaws in the traditional LFS workflow and the architectural limits of older automation tools like ALFS and jhalfs. It points out that these tools are unstable, depend on host environments, and don't have modern educational or cloud-native features.  The proposed Proof-of-Concept system uses deterministic environment setup, strict dependency closure, and a Two-Pass toolchain bootstrapping method to make sure that the Trusted Computing Base is safe by using hash-stable compiler outputs.  Amdahl's Law helps improve performance by using MAKEFLAGS=-j12 to speed up parallel compilation. 
         
         The Hierarchy of Computerized Functions (HCIS), UML diagrams, conceptual data modeling, and structured observability through detailed logging are all part of system design.  The results show that the Chapter 5 build time has been cut down to 45-52 minutes, the build success rate is 99.2%, and the peak memory usage is 6.20 GB, which is well within the =9 GB limit.  The prototype for the user-facing learning platform makes it easier to use by offering guided build submission, real-time monitoring, and structured log visualization.  The study finds that the hybrid WSL/chroot model is a useful, high-performance alternative to running only in the cloud, especially since Cloud Run has a 60-minute limit. It also finds that LFS can still be useful for learning while removing unnecessary operational burden.  The framework shows that it is possible to add LFS automation to modern DevOps-aligned workflows and academic settings.


SANTRAUKA 
         Šiame baigiamajame darbe sukuriama ir išbandoma automatizuota Linux From Scratch (LFS) kurimo sistema, kurios tikslas - sumažinti rankinio kompiliavimo trapuma, ilgaamžiškuma ir klaidu tikimybe. Darbe sprendžiamos pagrindines LFS metodologijos problemos, tokios kaip priklausomybe nuo pagrindines sistemos, ribotas atkuriamumas, operacinis nestabilumas ir sudetinga mokymosi kreive. Šie iššukiai iveikiami naudojant hibridine automatizavimo architektura, kuri jungia PowerShell pagrindu veikiancia orkestracija, WSL vykdymo aplinka ir chroot izoliacija.
         
         Analitineje dalyje nagrinejami tradicinio LFS kurimo proceso trukumai ir senesniu automatizavimo irankiu, tokiu kaip ALFS ir jhalfs, architekturines ribos. Pabrežiama, kad šie irankiai yra nestabilus, priklausomi nuo pagrindinio kompiuterio aplinkos ir nepasižymi šiuolaikinemis edukacinemis ar debesu kompiuterijos funkcijomis. Siuloma Proof-of-Concept sistema remiasi determinuotu aplinkos paruošimu, griežtu priklausomybiu uždarumu ir dvieju praejimu irankiu grandines ("Two-Pass") ikrovos metodu, siekiant užtikrinti patikimos skaiciavimo bazes (TCB) vientisuma per maišai stabilu kompiliatoriu rezultata. Našumo didinimui taikomas Amdahl desnis ir MAKEFLAGS=-j12 lygiagretus kompiliavimas.
         
         Sistemos projektavimas grindžiamas kompiuterizuotu funkciju hierarchija (HCIS), UML diagramomis, konceptualiu duomenu modeliavimu ir strukturuota žurnalu stebesena. Tyrimo rezultatai rodo, kad 5 skyriaus kurimo laikas sumažintas iki 45-52 minuciu, sekmes rodiklis siekia 99,2 %, o didžiausias atminties sunaudojimas 6,20 GB neviršija =9 GB ribos. Sukurtas naudotojams skirtos mokymosi platformos prototipas pagerina naudojimo patoguma, suteikdamas vedlio principu veikiancia kurimo pateikimo funkcija, realaus laiko stebesena ir strukturuota žurnalu vizualizavima. Tyrimas patvirtina, kad hibridinis WSL/chroot modelis yra našiai veikianti alternatyva debesu pagrindu vykdomiems procesams, ypac turint omenyje Cloud Run 60 minuciu apribojima, ir kad LFS išlieka vertinga mokymosi priemone sumažinus nereikalinga operacini sudetinguma. Sistema taip pat irodo, kad LFS automatizavima galima integruoti i šiuolaikinius DevOps metodus ir akademines aplinkas.



INTRODUCTION
         The process of creating a Linux operating system from scratch-sometimes called Linux from scratch, or LFS-is very rewarding. It is known to be somewhat difficult, but it gives you a really deep understanding of how a Linux system works from top to bottom, switching frequently between a number of user contexts, which may be hard and time-consuming.
         
      It appears that the typical Linux From Scratch build procedure often offers a somewhat delicate balancing proposition, where a single mistake or setting issue potentially will require repeated jumps between user sessions, whether it is root, the specified Linux build user, or actions within the chroot environment. This alone offers the promise of becoming a significant hindrance, certainly for a novice, such as the student Main, who will face these problems for the very first time.
      To tackle these issues, my thesis focuses on Linux from scratch, a visual automation framework I designed to make the LFS build process smoother and manageable.
      
      The traditional LFS build often feels like a tightrope, one wrong command or environment setting can result in having to constantly switch between user context (like root), the LFS user, or within the chroot environment), these demands can be a significant barrier, particularly for students like main who are attempting to overcome these challenges for the first time.
      
      However, building LFS manually using the steps provided in the documents poses considerable hurdles for easy adoption. The entire build process consumes about 10-15 hours for compiling, and it also requires careful execution of more than 200 commands involved in various build processes, along with a properly installed Linux host environment. Many build processes are often thwarted by environment-related inconsistencies, dependencies, and compilation errors, especially for users new to Linux operating-system level functionality. This reduces the use of LFS, even though it is very informative for computer science, IS, and cyber security students learning the details of operating systems.
      
      
      Additionally, the state of build automation and reproducibility that exists today and is germane to software development includes containerization, cloud-native systems, and Infrastructure as Code. However, the technological merit of LFS not with standing, it is deficient in contemporary technology that adheres to the tenets of DevOps and cloud computing. This not only presents a challenge for the adoption of LFS, but it also offers the opportunity of adopting new software development approaches within the established educational paradigm.
      
      Research Problem 
      
Existing solutions for the automation of Linux From Scratch, notably the Automated Linux From Scratch system (ALFS) and ALFS, handle various aspects of the automation process but clearly have several shortcomings. ALFS is defined using complex XML files and fails to leverage contemporary cloud containerization abilities. LFS provides automation for the script creation process but still demands a Linux host environment and fails to offer cloud-based processing. ALFS fails to provide a learning environment, web interface, or cloud-native hosting.

      The problem underlying the research work can be stated as: In what manner can the build system for Linux From Scratch be updated using containerization and cloud computing, and also provide a learning platform for the explanation of concepts of operating systems?
      
This problem statement relates to technological challenges, which include build reproducibility, resource isolation, and container processes, among others. Architectural challenges include scalable cloud infrastructure, state, and storage, among others. Lastly, the problem statement also relates to pedagogical challenges that include learning environment interaction, among others.
 
	Object of the Thesis

This thesis explores the automated build process for Linux From Scratch, specifically focusing on the build process for version 12.0 of Linux, along with the web-based learning platform. 
Issues discussed include: the process of compiling Linux, compiling the system libraries and building the kernel, building the environment for Linux, cloud assistance for executing the build process, the delivery of learning material, and the processes involving user interaction for the submission of their building and the receipt of the results.

	Aim of the Thesis

This work will design a cloud-based, containerized Linux From Scratch build automation system that also features an integrated educational platform. This will help achieve the following goals:
* Simplify the process of building.
* Provide reproducibility.
* Offer learning material for building operating systems.
For the achievement of these goals, the following objectives are formulated.
* To examine current approaches for the automation of Linux for Scratch (LFS) systems (ALFS), assess their limitations, and formulate the requirements for the new approach.
* To build a containerized build environment using Docker multi-stage build processes promote reproducibility, isolate dependencies, and are viable on the serverless container platform of Google Cloud Run.
* To provide build orchestration capability on cloud infrastructure using Firebase Cloud Functions and Google Cloud Run, facilitating asynchronous build processing, real-time build status monitoring, and automatically storing build results on Google Cloud Storage.
* To create an online learning platform using Next.js and React that provides interactive tutorials for LFS, terminal emulation, tracking, and documentation of the construction process.
* To assess the system for functionality (functional correctness, successful builds of Chapter 5 of the LFS book), performance (build time, resource use), and usability (ease of access of the interface, success of the learning process).


Difficulties and Limitations

Several technical challenges and limitations were encountered:
* Cloud Run Timeout Restrictions: The jobs that run on Cloud Run cannot take longer than 60 minutes, enforcing the requirement for a staged build process, since a large file system build, explained in Chapters 5-8, exceeds the time limit without using job chaining.
* Chroot Environment Complexity: To achieve the build isolation provided by the use of chroot within Docker containers, it is essential for the container to run with privileged execution and careful control of the filesystem namespaces
      


1. ANALYTICAL PART
         The analysis phase of this thesis will explore the current state of the problem space of build automation for Linux From Scratch, assess current state-of-the art solutions, and identify the requirements for a cloud-native, modernized implementation.
         
         This chapter will have three major parts. Section 1.1 will outline the problem definition stage, assessing the build technology of the Linux for Smartphone, the educational environment, the current challenges faced, and the current technological environment. Section 1.2 will examine the flow of data for both the manually performed Linux for Smartphone build process and the current technologies used, assessing the technology requirements. Section 1.3 will deal with requirements and technology, comparing other technologies used on the basis of defined parameters for justification of the used technology.
         
         The analytical approach will combine the literature review of the documentation of the Literature and Facts Study (LFS) with the comparison of automation tools (ALFS, jhaLFS) and the evaluation of the technology of containerization/cloud computing. This approach will highlight the requirements of the system design defined in the following chapters.

1.1 Problem Area Characteristics 
      1.1.1 Linux From Scratch Build Process Overview
         
         (Burgess, 1998)is a project that provides step-by-step guidelines for building a customized Linux operating system using the source code. This project differs from other Linux distributions, such as Ubuntu, Fedora, Debian, and so on, because other Linux distributions provide binary packages for users, but Linux From Scratch provides guidelines for compiling the operating system components manually, starting with the operating system building blocks (binutils, GCC, glibc) up to the Linux kernel. It provides total transparency for building the operating system.
         The LFS 12.0 build process, which this system implements, consists of eight chapters of increasing complexity.

         Chapters 1 through 4 form the initial phase, which includes the identification of the requirements of the host system, forming a partition, and acquisition of the source packages, aggregating around 3.8 GB of tarballs.
         
Chapter 5 The temporary toolchain construction using cross-compilation methods is discussed. This chapter details the construction of a minimal, host-agnostic GCC, binutils, and glibc toolchain that consists of 15-18 packages (M4, ncurses, Bash, coreutils, and other basic tools), which will take around 4-6 hours.

The entire manual process requires 10-15 hours of compilation time (dependent on the computer hardware), the careful execution of over 200 distinct commands, and monitoring for errors. Even the expert user will often experience build errors, often because of the absence of host dependencies, incorrect syntax, or environmental mismatches.

      1.1.2 Educational Context and learning objectives
         
         LFS is a learning tool for computer science, information systems, and cybersecurity students that helps them attain familiarity with the internal workings of operating systems through hands-on building. Some of the paramount learning objectives are:
* Understanding the toolchain: The knowledge of the bootstrap process whereby the compiler compiles itself, involving the three-stage build process of the GCC compiler, differences between static and dynamic linking, and the patterns of dependencies among the system libraries.
* System Architecture: Analysis of the Linux system directory structure (for example, /bin, /lib, /etc, and /usr) for the purposes of explaining the conceptual difference between system software and user software, along with the requirements of POSIX compliance.
* Build systems: An examination of the use of autoconf/automake build systems, focusing on the construction of Makefiles, how they can be interpreted, and typical patterns of compilation used among various software packages.
* Skills for Troubleshooting: Building skill sets in compiler message interpretation, analyzing dependency-related problems, and addressing conflicts generated during the configuration phase.
         The steep learning curve and time involved in performing Linux From Scratch by hand create obstacles for accessibility. Those who cannot access Linux environments, those with limited time for the time-consuming compilation phases, or persons discouraged by the command line-intensive process often do not pursue the Linux From Scratch project. An automated cloud platform that integrates learning aids will help mitigate these factors, along with other benefits.
         
      1.1.3 External Environment and Technological Trends
         
         The contemporary software development landscape exhibits several trends relevant to LFS automation: 
* Adoption of containerization. The use of Docker containers since 2014 has grown considerably, and container technology is accepted throughout the IT industry for hosting applications, DevOps, and reproducible builds. It is estimated that Docker Hub contains over 13 million container images, and containerization has been introduced into computer science courses at the undergraduate level.
* Cloud-Native Architecture. The shift from on-premises infrastructure and the implementation of cloud computing (IaaS, PaaS, and SaaS) services introduced new concepts of scaling and deploying applications. Cloud-based serverless computing environments, such as Google Cloud Run, Amazon Web Services Lambda, and Azure Functions, allow for the processing of computationally heavy tasks without the need for infrastructure management.
* DevOps processes, such as CI/CD integration and delivery pipelines, IaC, and testing, have become mainstream. Modern software developers expect the following: the reproducibility of a build, versioning of infrastructure, and the automated process of deployment. Such expectations were not possible in the previous, non-DevOps approach, because the processes were mostly manual.
* The use of educational technology is also influenced by the growing integration of interaction features like virtual labs, browser terminals, and progress tracking systems. The evolution of learning technology on the web has also been driven by the growing effects of the COVID-19 pandemic.

         These concurrent trends also offer opportunities and expectations. Such users familiar with modern development approaches will expect the automation of the Lifestyle Framework Solution to take advantage of containerization, cloud technology, and easy-to-use web interfaces, rather than requiring Linux platforms and manual setup.

      1.1.4 Current Challenges and User Pain Points
         
         Analysis of LFS community forums, mailing lists, and user feedback reveals consistent challenges:
* Host System Requirements and Compatibility: The requirement for using LFS is that the host system software must run on Linux, with particular versions of the tool chain software (GCC version 4.9+ and binutils version 2.13+), and also a compatible shell (like bash), among other requirements. For people using other systems, for example, Windows or macOS, there will also be the need for virtualization, which also brings along extra complexity. There might also be conflicts for Linux users.
* Error Recovery: In-process build errors, which are often the result of normal considerations like storage space, memory, and mismatched dependencies, rarely have well-structured recovery steps. This problem results in users performing a rebuild process.
* Environment Reproducibility: Minor variation between host environments, ranging from library versions, kernel choices, and filesystem distributions, causes irregularities in the build process. Irreproducible build processes, where a successful build on one host fails on the next, following the exact same steps, often cause confusion.
* Learning Curve: The LFS Book offers very detailed procedural discussions, but it is assumed that one knows Linux very well. Topics like "chroot", cross-compiling, and the bootstrapping of toolchains are mentioned only briefly, which can make it difficult for new users to understand the conceptual bases.
* Artifact Management: Finished LFS systems are modeled using directory trees or filesystem images. There is a void regarding the support of sharing, versioning, or other processes of the finished system artifacts.

         Such challenges often trigger the need for the implementation of an automated system that aims to improve reproducibility (facilitated by containerization), accessibility (enabled by the web interface), time management (facilitated by cloud-based execution), and learning (facilitated by documentation).
         
      1.1.5 Business and Educational Value Proposition
         
* For the educational institution, the benefits of using the automated Linux From Scratch (LFS) system are the following:
* Standardized laboratory environment for operating systems-related coursework.
* Lower pressure on the institutional IT infrastructure, since the build processes will take place through the cloud.
* Scalability suitable for class sizes between 20 and 100 students. Scalability suitable for class sizes between 20 and 100 students.
* Integrated progress monitoring and assessment capabilities. 
* For individual learners, the system offers:
* Removal of barriers for host-system configuration.
* The ability to learn the concepts of the LFS without a prior commitment of ten or more hours per session.
* Interactive learning resources that are incorporated into the build process.
* Reusable build artifacts that support experimentation.
* For cybersecurity experts, awareness about LFS helps:
* Knowledge of system level attack surfaces
* Building personalized and secure systems
* Understanding the Concepts of the Trusted Computing Base
* A Foundation for Security Analysis of Embedded Systems
* It is the convergence of educational value, technological feasibility, and utility that forms the rationale for the thesis project.

1.2 Local LFS Build Architecture and Wizard Automation
         
         The next parts change the information flow analysis to fit with the main idea behind the LFS Automated Build project: Local-First, Transparent Execution powered by a modern frontend wizard and strong local automation scripts. This analysis critically examines the architectural constraints of both legacy automation (ALFS/jhalfs) and the theoretical Cloud-Native Continuous Integration (CI) methodology, ultimately validating the existing local architecture.
         
      1.2.1 Paradigm 1: The Fragility of the Manual LFS Build Flow
         
         The Fragility of the Manual LFS Build Flow The Manual LFS process represents a very sequential, single-threaded processing of information that requires human involvement and operation. Although it retains its educational significance as a teaching exercise, this model is not very useful in a practical setup owing to its inherent statefulness and vulnerability of operations.
         
         This means that there is a susceptibility to corruption in this process, as it is evidenced by unfinished patching, procedural inaccuracies, and a misalignment of sources. This set of properties, taken as a whole, suggests a situation that has a very high amount of Operational Risk as well as a lack of reproducibility. This lack of reproducibility translates to a set of compile results that are described as being "extremely irregular and prolonged, taking usually a whole month" in which "a lot of triaging of failures" takes place rather than actual compilation.
         
         This large variability means that a large amount of human debugging effort needs to be exercised for determining the critical path in this software, further increasing compilation time due to heavy reliance upon very qualified personnel. Also, a normal failure mode for this compilation stage can originate from delicate dependencies of this software upon other components of this software package, including the lack of host software packages like a set of utilities including texinfo, along with improper setting of environmental variables. 
         
         This has been shown by compilation failures due to improper toolchain alignments in Glibc. To counteract a risk due to installing software packages onto a host computer, a strategy of isolation using a separate LFS user, as has been described in Chapters 5 and 6 of a standard manual for Linux From Scratch, brings in a fresh vulnerability for this software component.

      1.2.2 The Architectural Limits of Legacy Automation (ALFS/jhalfs)
         
         "Legacy automation projects, especially in the form of jhalfs, which is the official implementation of ALFS, improve computational efficiency but are limited by major architectural and stability issues."
         
         Jhalfs gets commands from the LFS XML sources and runs them with Bash scripts that are controlled by a Makefile framework. This shows that it can compile quickly, full builds take about 30 minutes on high-performance hardware (not including testing).   On the other hand, the project's official status makes it less useful as a dependency for production.  It is kept up to date as a "rolling release," but there is a "lack of manpower" and it is clearly marked as "not stable." 
         
         Using Makefiles for execution and error recovery is still an important, stateful strategy when it comes to architecture. If a package doesn't work, you have to clean up the local environment by hand or with a script before you can try again.   This dependence on cleaning state makes it possible for a "dirty" build to happen again, which could lead to outputs that aren't always the same.

      1.2.3 Proposed System: Local-First Philosophy and Architecture
         
         The LFS method requires that you immediately separate yourself from the libraries and tools that are already on the host system. The host environment, which can be Ubuntu, Fedora, or a custom distribution, adds environmental variables, library versions, and patches that make sure the build can't be reproduced. To fix this, the first step of cross-compilation (Pass 1) builds a temporary toolchain that is specifically for the new system architecture, which is defined by the triplet $LFS_TGT=x86_64-lfs-linux-gnu.
         
          This process of cross-compiling follows the principle of dependency closure. When you build parts like Binutils Pass 1 and GCC Pass 1, you set them up with flags like --target=$LFS_TGT and, most importantly, --disable-shared. If core components were dynamically linked at this point, they would depend on libraries on the host system, especially the host Glibc. This dependency would cause the resulting toolchain to fail or have symbols that don't match up when run inside the newly built, minimal LFS root. 
         
         The Filesystem Hierarchy Standard (FHS) says that you should make a separate /tools directory and link it to the temporary toolchain location. This structure makes it clear where the trust line is. The files in /tools are separate, temporary binaries that are only used to start up the final system. The execution environment makes sure that the new LFS build process uses its own new, separate tools right away after installation by putting the /tools path before the standard host paths in the $PATH variable. This stops host utilities from messing up the build process by mistake. This separation is very important for achieving the level of environmental immutability that the thesis's main goals are looking for.

      1.2.4 The Two-Pass Build Rationale: GCC Bootstrapping for Verification
         
         The need for a two-pass toolchain build, which includes re-compiling GCC and Binutils (Pass 2) inside the isolated LFS environment, goes beyond just configuring the system to address serious concerns about its integrity and trust. The host operating system's compiler compiles the binary that was made in Pass 1. The host compiler may have bugs or security features that the resulting Pass 1 binaries could inherit, even though it works. 
         
         The next step, Pass 2, takes place in the newly isolated chroot environment. It makes the Pass 1 compiler, which is now running in the LFS environment, recompile itself using the LFS system's new C library (Glibc) and kernel headers. In compiler engineering, this process is called "bootstrapping," and it checks the integrity of the whole toolchain stack. If the Pass 2 compiler binary is the same as the Pass 1 binary, it means that the system libraries (Glibc, headers) are installed correctly and that the compiler can compile itself without any problems. Any difference means that there is an instability or dependency misalignment that needs to be fixed.
         
         This whole mechanism directly meets the automated system's non-functional requirement (NFR) for reproducibility (NFR-R01). The two-pass verification ensures that the LFS kernel and userland will be consistent, no matter what the initial host environment is, which could be anything. This strict verification process turns the LFS build into a quality-assured, self-validating system instead of a series of steps. This directly supports the Cyber Security program's focus on trusted computing bases.
1.3 Isolation Models, Performance, and the PoC Justification
         
         The main difference in the architecture of the thesis is between the stated goal of using high-isolation, short-lived Google Cloud Run containers and the actual implementation, which uses a hybrid WSL/chroot orchestration model. This necessary technical change must be backed up by a thorough look at isolation mechanisms and performance.

      1.3.1 Comparative Analysis of Isolation Mechanisms 
         It is important to understand the architectural limits of chroot isolation in comparison to modern containerization technologies such as Docker. The LFS scripts use chroot mainly to isolate filesystems by limiting processes to a new root directory. 
         
         This is enough to keep the build process separate from the host's main binaries, but it doesn't provide much security or operational separation. Processes in the chroot use the host's kernel, PID namespace, and networking stack. Docker and cloud container services, on the other hand, use kernel features like Linux Namespaces and control groups (cgroups) to provide multi-layered isolation. This allows them to virtualize PID, network, and user environments, making them better for running code that isn't trusted or for making environments more stable.   
         
         But the best thing about chroot in the LFS context is that it doesn't slow down performance very much. Running computation-heavy compilation tasks inside a chroot gets CPU throughput that is almost the same as the host system's because it uses very few kernel layers or hypervisor functions.
         This performance edge is the main reason for the PoC pivot. The thesis objectives require performance (NFR-P01), particularly concerning the compilation phase, which usually takes 10 to 15 hours for a full manual build. Cloud Run, the intended cloud platform, has a strict execution timeout that is usually set to 60 minutes. It is impossible to do the full LFS Chapter 5-8 build, which includes hundreds of configuration and compilation steps for packages like GCC, in this short amount of time. 
         
         To validate the core orchestration logic and achieve demonstrably fast compilation times (NFR-P01), the most resource-intensive compilation stage must be executed in a high-fidelity, local environment-the WSL/chroot Proof-of-Concept-prioritizing performance and process continuity over the multi-layered security isolation ideal of full cloud deployment.

      1.3.2 Justification of the Hybrid WSL Architecture
         
         The chosen architecture uses Windows Subsystem for Linux (WSL) to get around a big problem for users: they need a specific Linux host environment. Putting the Linux build environment inside WSL makes it a lot easier for people who use Windows or macOS to use Linux. This makes it easier to set up traditional virtualization.   
         
         The PowerShell wrappers, like BUILD-LFS-CORRECT.ps1, are the API gateway for the host system. They made a stable, repeatable way to start and control the build process from the host machine. They take commands from users that are at a high level and turn them into the Bash commands that run on Linux. This mixed approach meets the Non-Functional Requirement of Portability (NFR-P02) because it makes the hard build process easier to handle in different user environments. This shows that it fully answers the questions about accessibility that were raised in the introduction.
1.4 Analysis of Current Information Flow
         
         It is very important to look at how information flows in order to figure out the system's architecture and compare the current methods with the proposed automated flow.
         
      1.4.1 Legacy Information Flow (Manual LFS)
         The manual LFS build has an information flow that goes in order and is controlled by people. This makes it very easy for mistakes and contamination to happen.
         
* Steps in the flow: Human input (command) $?$ Host Shell Run Compilation to Mutable State (the LFS directory) and then to Human Output (an unstructured log). ? Debugging by Humans
* Vulnerability: The flow of information depends on the host environment's initial state (GCC and binutils versions) and the memory of the person operating it (correct user context, chroot execution, and correct flags). Errors in managing dependencies or environment variables can cause builds to fail, which means that state cleanup must be done by hand and cannot be repeated, and debugging takes longer. The output is a stream of text that isn't organized (standard output), which makes it very hard to monitor automatically.


      1.4.2 Proposed Information Flow (Automated and Scripted PoC)
         
         The cloud-native architecture controls and automates the flow of information so that it can be easily repeated and audited. The local PoC scripts use mounting and isolation techniques to make this flow look the same.
         
* Steps in the Flow: Host Orchestrator (PowerShell/Bash) Separate Environment (WSL/chroot) ? Running the script Compilation ?Structured Output (BUILDLOG) Managing artifacts (system image and provenance attestation).
* Setting up the environment: init-lfs-env.sh and build-lfs-complete-local.sh set the execution context, especially by setting the cross-compilation triplet and giving the temporary toolchain path priority. This flow makes sure that the right tools are used before installing system binaries, which is very important for the dependency closure principle.
* Isolation Transfer: chroot-and-build.sh takes care of the important job of transferring control, binding the host virtual filesystem, and running the final build script in the isolated environment. This is the main architectural change, which shows that it is possible to switch from cross-compilation to native, self-hosted compilation.
* Output of Information: The script /build-lfs-in-chroot.sh uses structured logging by calling the log() function and tee -a "$BUILDLOG". This changes the information that comes out of an opaque text stream into a resource that can be used for automated monitoring and finding problems (Structured Observability).


      1.4.3 Identification of Key Issues to Resolve
         The system directly addresses five major problems in the Linux From Scratch (LFS) community, linking each one to a specific Non-Functional Requirement (NFR) of the thesis.
         
         Table 1
          
Issue to ResolveNFR AddressedProblematic ImplicationIrreproducible ToolchainsReproducibilitySmall, hard-to-track changes in the host environment cause binary output that isn't always the same, which hurts system trust.Excessive Compilation TimePerformanceThe 10-15 hours it takes to compile makes it hard to access and goes against cloud service time limits, like the 60-minute Google Cloud Run timeout.Host System DependencyUsability/AccessibilityThe requirement for a specific Linux host environment makes it harder for people who don't use Linux (Windows/macOS) to learn virtualization first, which is not necessary.Operational Fragility (State)MaintainabilityWhen a build fails, you have to clean up the state by hand (recovering from a "dirty" build), which can take weeks and raise the risk of operational failure.Lack of System IntegritySecurity/AssuranceThe final artifact doesn't have any metadata about the build environment and script execution that can be checked, which makes it hard to trust, which is not acceptable in modern TCB requirements.            Table 1: Key Issues to Resolve
(Source: Made by Shubham Bhasker) 

      1.4.4 Synthesis of Analytical Findings and Technical Justification (Local Project)
         This part brings together the theoretical analysis and the main implementation choices made in the local project scripts to meet the need for very technical detail.
         Table 2
          
Analytical Finding/PrincipleSynthesis of Script ImplementationJustificationTwo-Pass Toolchain TrustBinutils Pass 1 (build-lfs-complete-local.sh) was set up with --target=$LFS_TGT and --disable-shared. GCC Pass 2 (build-minimal-bootable.sh): The target Glibc libraries were used to recompile inside the final LFS environment.Makes sure that the whole toolchain is compiled on its own and checks for integrity, which closes dependencies and gets rid of the host compiler's unpredictable effects.Memory StabilityBash Configuration: Both the temporary toolchain (implied) and the final Bash package (build-lfs-in-chroot.sh) have the critical flag set: --without-bash-malloc.Reduces the chance of segmentation faults and crashes during heavy, parallel compilation by making Bash use the stable Glibc memory functions.Minimalism and Auditability	Python Configuration: The Python build uses the following flag: --without-ensure pip.Follows the principle of minimal TCB by making it clear that pip and setup tools package management components cannot be combined, which keeps control over the system's package management footprint.Improving Parallel PerformanceAll of the core compilation scripts (init-lfs-env.sh, /build-lfs-in-chroot.sh, build-minimal-bootable.sh) set and enforce export for MAKEFLAGS. MAKEFLAGS=-j12.1Directly addresses I02 (time) and NFR-P01 by maximizing parallel throughput. The chosen factor ($N=12$) is an engineering balance that tries to get the most out of parallelizable compilation time while keeping the cost of managing threads as low as possible (Amdahl's Law).10LFS Path IsolationPATH Management: init-lfs-env.sh gives the temporary toolchain priority with export PATH=$LFS_TOOLS/tools/bin:/usr/bin:....Enforces the FHS structure for LFS Chapter 5, making sure that the new toolchain binaries run over older host binaries that may not be compatible, which sets up the trust boundary that is needed.            Table 2: Analytical Findings and Technical Justification
(Source Shubham Bhasker) 



         APPROVED
Supervisor: 
         Student: Shubham Bhasker
         Date 2025-12-11
2 TECHNICAL TASK
1. TITLE OF THE THESIS (TITLE):
         LINUX FROM SCRATCH (LFS) AUTOMATION FRAMEWORK: A Cloud-Native Method for Building a Trusted Computing Base.
2. CONTENT OF THE ANALYTICAL AND RESEARCH WORK:
2.1 Market Analysis: Critique of manual LFS fragility and limits of legacy automation (ALFS/jhalfs); the main access problem is build time (10-15 hours).
2.2 Build Algorithms: Examination of the Two-Pass Toolchain for GCC integrity, Dependency Closure (static linking in Pass 1), and the application of Amdahl's Law to parallel compilation (MAKEFLAGS=-j12) for throughput enhancement.
2.3 IS Benchmarking: Comparing chroot (which is fast) to Docker (which is very secure) to explain why the Hybrid WSL/chroot Proof-of-Concept architecture is a good idea.
3. DESIGN SYSTEM FUNCTIONS: 
3.1 Environment Setup: Define $LFS, $LFS_TGT, and the toolchain path priority. This makes sure that FHS is followed and LFS Path Isolation is in place, which is very important for managing dependencies.
3.2 Cross-Toolchain: Use the critical flag --disable-shared to run LFS Chapter 5 cross-compilation (Binutils/GCC Pass 1). Sets up a host-agnostic compiler for the native phase (Dependency Closure).
3.3 Isolation/Native: Set up kernel mounting (chroot-and-build.sh) and run native compilation with stability flags. Keeps core system utilities separate from each other and makes the most of memory stability.


3.4 Artifact/Logging: Get the structured output ($BUILDLOG) and package the final LFS directory/kernel image artifact. Gives structured observability and a record of system provenance that can be checked. 
4. SYSTEM DESCRIPTION DOCUMENTATION AND INSTRUCTIONS: 
4.1 User Manual: Instructions which highlight the PowerShell wrapper (BUILD-LFS-CORRECT.ps1) as the easy way to start a build via an API gateway.
4.2 Programmer Guide: Instructions for environment setup, maintenance of build scripts, and explanation of the chroot-and-build.sh kernel binding sequence and package configurations.
5. SYSTEM DESIGN TOOLS, SOFTWARE AND HARDWARE REQUIREMENTS:
5.1 Design Tools: Use case, sequence, component, and activity diagrams in UML to show how orchestration and flow control work.
5.2 Core Software: GNU Toolchain (Binutils 2.41, GCC 13.2.0, Glibc 2.38) and script execution environments (Bash, PowerShell).
5.3 Operating Env: Windows 10/11 PowerShell controls the hybrid WSL architecture (Windows Subsystem for Linux).
5.4 Hardware Specs: Multi-core CPU (at least 4 cores)  = 8 GB of RAM, at least 50 GB or more of high-speed storage, specifically for parallel compilation
6. SYSTEM TESTING AND EVALUATION: 
6.1 Control Set: Make test C/C++ programs (/tmp/test.c and /tmp/test.cpp) and source tarballs to check that cross-compiler linking works.
6.2 Test Evaluation: Check the integrity of the toolchain by running version checks and compilation tests check the performance by looking at the logged execution time; and check the TCB assurance by seeing if the Binutils/GCC Pass 2 test passes.
6.3 Comparison/Analogues: This is a comparison of the system's reproducibility (NFR-R01) and portability (NFR-P02) against the known problems with manual builds and old automation tools (ALFS/jhalfs).
7. THESIS PRESENTATION REQUIREMENTS
7.1 Thesis structure: Introduction, Analytical Part, Technical Task, Project Part, Implementation, Conclusions, Recommendations, References, Annexes.
7.2 Comprehensive thesis following the methodological guidelines provided.
7.3 Oral presentation and pptx presentation of a BA thesis during the defence (6-8 min.)


3 PROJECT PART
         The Project Part describes in detail how the Linux From Scratch (LFS) Automation Framework Proof-of-Concept (PoC) was designed and built. This chapter connects the ideas from the Analytical Part (Chapter 1) to the formal specifications from the Technical Task (Chapter 2). It goes into detail about the ISCS Methodological Guidelines' requirements for physical and logical architecture, implementation mechanisms, algorithms, and validation protocols. Because automating the LFS process is so complicated, there needs to be a strong discussion about the design trade-offs that were made to make sure the system works well and is secure.
         
3.1 Project Aim and Architectural Justification
         
         The functional and non-functional requirements for the Linux From Scratch (LFS) Automation Framework Proof-of-Concept (PoC) were carefully laid out to make sure the system is reproducible, fast, and easy to use. This directly addresses the main problems with the manual build process.
         
          This table shows the requirements in a clear and concise way, with a focus on the main purpose of each constraint.
         
      3.1.1 Functional Requirements
         We carefully wrote down the functional and non-functional requirements for the Linux From Scratch (LFS) Automation Framework Proof-of-Concept (PoC) to make sure the system is easy to use, fast, and can be reproduced.  This directly fixes the biggest problems with building by hand.


           This table makes the requirements easy to understand by focusing on the main purpose of each constraint.

IDRequirement NameDescriptionFN-1Build AutomationThe PowerShell wrapper (BUILD-LFS-CORRECT.ps1) must run the entire Chapter 5 toolchain build without any manual shell interaction. This makes sure that the execution scripts (init-lfs-env.sh, chroot-and-build.sh) set up and run the chroot stage without any user input.FN-2Bootable Artifact OutputWhen you have time, use the same chroot environment to make a minimal bootable artifact (kernel + init scripts) and make sure the final artifact file is in the lfs-output/ directory.FN-3Learning Platform IntegrationShow the automated build flow and logs in the Next.js/React learning platform for teaching purposes. This includes a build submission wizard, a log viewer that shows streamed logs, and progress indicators that show where packages end.FN-4Build Success Rate GoalGet your Build Success Rate (Successful builds / Total builds) × 100 to be at least 90%.FN-5Log AvailabilityFor every completed build run (100% availability), there must be a main output log file (BUILDLOG) with the required package markers.            Table 3: Functional Requirements
            (Source: Made by Shubham Bhasker) 


      3.2.2 Non-Functional Requirements
         
         Non-Functional Requirements set the standards for the system's performance, integrity, and operational resilience in terms of quality, limitations, and success.
         
IDRequirement NameDescriptionNFN-R1Host-Independent OutputMake sure that the toolchain binary outputs are the same no matter what host they are running on (for example, different versions of Windows, WSL images, or local Linux distributions).
NFN-R2Environment ControlYou need to set up the /mnt/lfs directory structure with strict permissions and environment variables ($LFS_TGT, PATH prioritization of /tools) that are always the same.
NFN-R3Artifact Hash StabilityA 100% match on the SHA256 hash comparison must show that toolchain artifacts are hash-stable across multiple local runs with the same sources.
NFN-P1 - PerformanceBuild Time DocumentationFor empirical performance assessment, the total build time on the PoC hardware must be measured and recorded in the build-metadata-*.txt file.
IDRequirement NameDescriptionNFN-P2Local Resource UsagePeak RAM usage during resource-intensive compilation phases (GCC and Glibc) must be constrained to $\leq 9$ GB.
NFN-P3UI ResponsivenessThe user interface's Time to Interactive (TTI) must be less than or equal to 2 seconds.
NFN-U1 - Usability / ObservabilityBuild ObservabilityLet users check on the progress of their builds without having to log into the WSL environment via SSH.  Logs must be sent to BUILDLOG and saved locally in lfs-output/.
NFN-U2Recovery GuidanceGive clear instructions on how to recover from failed packages after state cleanup so that operators can pick up the build where it left off without having to start over.
NFN-U3Log RetentionFor every run, the build log (BUILDLOG) must be kept (100% retention).
NFN-S1Privileged Operations MitigationChroot needs privileged operations (sudo inside WSL), but to protect against it, chroot should only happen against /mnt/lfs, use as few bind mounts as possible, and not allow network access during sensitive compilation stages
NFN-S2Isolation ScopeSecurity compliance for the chroot isolation scope must only apply to the /mnt/lfs directory.
            Table 4 Non-Functional Requirements
            (Source: Made by Shubham Bhasker)

      3.1.3 Restatement of Project Aim and Objectives
         
         The main goal of this thesis is to create a containerized, automated LFS build system that works with an educational platform. This architecture is designed to achieve three main objectives: streamlining the traditionally complex LFS build process, ensuring strong reproducibility, and supplying extensive educational resources for operating system development.
         
         The design decisions made in this project directly fix the problems with the system that were found during the analysis phase. The automation framework is specifically designed to deal with the high operational risk of the manual flow. This is because it has a "delicate balancing proposition" where even small mistakes need complicated debugging and frequent, time-consuming switches between user contexts (root, LFS user, or chroot environment). Also, the system architecture makes it easier to get started because it doesn't need a certain Linux host environment and the manual build and compilation phase usually only takes 10 to 15 hours.


      3.1.4 Architectural Rationale: Justification of the Hybrid WSL/chroot Proof-of-Concept (PoC)
         
         The original plan for the architecture was to use Google Cloud Run to build a cloud-native application that could run on a serverless container. But a key engineering limitation, the Cloud Run execution timeout, which is usually set at 60 minutes, made it impossible to complete the full LFS build process on that platform, which can take up to 15 hours of continuous compilation.
         
         This fundamental limitation required an architectural pivot, leading to the adoption of a hybrid, local-first Proof-of-Concept (PoC) model leveraging the Windows Subsystem for Linux (WSL) and the native Linux chroot mechanism. This approach prioritizes performance and process continuity over the multi-layered security isolation inherent to a full cloud deployment
         
* Prioritization of Performance: We chose to use chroot isolation because it would speed up computation (a non-functional requirement for performance). Running computation-heavy compilation tasks inside a chroot environment gives you a big performance boost because it avoids the extra kernel layering and hypervisor functions that come with full virtualization or robust container technologies like Docker. This means that CPU throughput is almost the same as on the host system. This high-fidelity, local execution environment allows for demonstrably fast compilation times, validating the core orchestration logic necessary for the resource-intensive Chapter 5-8 build phases, which otherwise violate the cloud service time constraints.

* Fulfillment of Accessibility: We chose to use chroot isolation because it would speed up computation (a non-functional requirement for performance). Running computation-heavy compilation tasks inside a chroot environment gives you a big performance boost because it avoids the extra kernel layering and hypervisor functions that come with full virtualization or robust container technologies like Docker. 

* This means that CPU throughput is almost the same as on the host system. This high-fidelity, local execution environment allows for demonstrably fast compilation times, validating the core orchestration logic necessary for the resource-intensive Chapter 5-8 build phases, which otherwise violate the cloud service time constraints.

3.2 Logical Structure of the Automated Build System
         The Hierarchy of Computerized Functions (HCIS) describes the system's logical structure. It includes both the user-facing web platform (conceptual design) and the local execution environment (PoC), which is where the system is actually built.
         
      3.2.1 Hierarchy of Computerized Functions (HCIS)
         
         The system capabilities are logically decomposed into several hierarchical groups, ensuring clear separation of concerns, from user interaction to deep kernel execution.


            Figure 1: Hierarchical Tree Diagram
            Source: Made by Shubham Bhasker (2025)
* User Management: Standard functions that manage user access, such as registration, authentication, and session management, are very important for the integrated educational platform.
* Learning Platform: Functions that are specifically for educational purposes, like Module Navigation, Content Rendering, Progress Tracking, and Terminal Emulation, which includes log streaming for structured observability
* Build Management: The main unit for orchestration.  This includes Build Submission (with validation and queue management), Build Execution (orchestrating compilation), Progress Monitoring (streaming status and logs), and Artifact Management (uploading and storing metadata).
* Local Build Orchestration (PoC): This layer contains the main scripts that control the state changes on the local host.  The PowerShell wrapper is the main way to get in.
* Environment Initialization: This is done by init-lfs-env.sh, which sets up the deterministic LFS directory structure (/mnt/lfs, /tools), sets environment variables like the cross-compilation target ($LFS_TGT), and makes sure that the temporary toolchain has the right $PATH priority.
* Chroot Transition: The chroot-and-build.sh script manages the necessary state change, involving the binding of virtual filesystems (/dev, /proc, /sys) from the host into the /mnt/lfs root, establishing the hermetically sealed compilation environment.


      3.2.2 Conceptual Data Model and Entity Relationships (CDM)
         
         The system's Conceptual Data Model is based on the data entities needed for job orchestration and status tracking. These are mostly stored in Google Cloud Firestore in the conceptual cloud design.
         
            Figure 2: Constraint-Solution Mapping Flowchart 
            Source: Made by Shubham Bhasker (2025)
            
* Users: Stores important user data, such as userId, email, and denormalized fields like totalBuilds and an array of buildId references. This makes queries faster for personalized user dashboards.
* Builds: The main part of managing jobs.  For real-time frontend rendering (Build Observability, NFN-U1), it keeps track of execution status (status), configuration (lfsVersion, buildOptions), timing metrics (submittedAt, startedAt, completedAt), and important denormalized information like currentPackage and build progress (0-100%).  It also has artifact references, like artifactPath and artifactSize.
* BuildLogs: A time-series entity that can store a lot of streaming log entries, sorted by buildId and timestamp.  Each entry has information like the level, message, and packageName being compiled, which turns the usual unreadable text stream into structured, auditable data.

         
            Figure 3: System Context Diagram
            Source: Made by Shubham Bhasker (2025)
            
            
            Figure 4: Data Flow Diagram 0
            Source: Made by Shubham Bhasker (2025)

         
            Figure 5: Data Flow Diagram 2
            Source: Made by Shubham Bhasker (2025)
         
         
            Figure 6: Data Flow Diagram 2
            Source: Made by Shubham Bhasker (2025)

      3.2.3 System Dynamics and Build State Diagram
         
         The system dynamics determine how the execution flows and how errors are handled.  The build job moves through a set state diagram: SUBMITTED > PENDING > RUNNING > COMPLETED | FAILED.
         
         The first thing to do in the activity workflow is read the configuration and set up the environment.   Next, you need to get the source packages.  This compares the checksums to the source tarballs, which are about 3.8 GB in size.    The Build Toolchain loop does most of the work. It goes through the 18 basic LFS packages.   
         
         The most important change is from the RUNNING state to the terminal FAILED state.    If there is a compilation error, this change happens right away.    The system sends a structured errorMessage to the builds entity and then stops.    This proactive logging helps operators figure out exactly what went wrong and get the system back to where it was.  This is better than older systems that were weak and needed a lot of work to clean up.
         
            Figure 7: Entity-Relationship Diagram (ERD)
            Source: Made by Shubham Bhasker (2025)

            
            Figure 8: Build Submission Sequence Diagram
            Source: Made by Shubham Bhasker (2025)
            Figure 9: Build Lifecycle State Machine
            Source: Made by Shubham Bhasker (2025)
         
      3.2.4 Formal Description of LFS Build Procedures and Optimization
         
         Two formalized procedures are what keep the system technically sound: the strict use of the Two-Pass Toolchain technique and the performance optimization required by Amdahl's Law.
         
* Phase I: Host-Agnostic Cross-Compilation (Pass 1): The first step, which is done by build-lfs-complete-local.sh, uses the host compiler to cross-compile core parts (Binutils and GCC Pass 1). The configuration uses important flags like --target=$LFS_TGT and, most importantly, --disable-shared.  Using --disable-shared makes sure that Dependency Closure happens, which means that the temporary toolchain binaries that are created are statically linked and don't depend on the host Glibc libraries, which can change at any time.  This makes the first toolset, which is clean and free of any problems, in the separate /tools directory.
* Phase II: Self-Validation (Pass 2/Bootstrapping): After the necessary LFS Glibc libraries have been installed, this phase happens inside the isolated chroot environment.  Using the Pass 1 compiler and the new LFS system libraries, the script re-compiles GCC and Binutils (Pass 2).  If the Pass 2 binary works the same way as the Pass 1 binary (hash stable), it shows that the LFS system libraries are properly integrated and that the whole toolchain stack is consistent and not affected by the original host environment.  This change makes the build process a quality-assured, self-validating system instead of just a series of steps.

      3.2.5 Formal Calculation: Performance Optimization via Amdahl's Law
         To deal with the problem of Excessive Compilation Time (I02) and meet , the system uses parallel processing by setting export MAKEFLAGS=-j12 across all core compilation scripts. Amdahl's Law is used to explain this choice. It predicts the theoretical speedup that can be achieved by parallelization. Amdahl's Law says that the overall speedup (S) of a program is limited by the part of the program that can't benefit from the improvement (the serial part).
         S = 1/((1 - P) + P/s)
         The number of cores, N=12, is the speedup factor, and P is the part of the task that can be done in parallel (the compilation phase). The compilation phase (P) can be done in parallel (about approx 0.95), but the overall speedup is limited by the parts that have to be done in order, like file I/O, package configuration (./configure), and installation (make install).  The engineers chose N=12 because it strikes the best balance between maximizing parallel throughput and reducing the diminishing returns and extra work that would come from using a core factor that is too large.


3.3 Information Architecture and Data Specification
         
         The LFS build can be repeated because the execution environment is set up in a way that is both deterministic and separate.  Key architectural choices determine the input state.
         
      3.3.1 LFS Path Isolation
         
         The init-lfs-env.sh script does important PATH Management, making sure that the temporary toolchain binaries are given priority over host utilities that might not work with them.  This path is set to export PATH=$LFS_TOOLS/tools/bin:/usr/bin:.....  This strict hierarchy makes sure that LFS Chapter 5 follows the FHS structure and sets the trust boundary that needs to be there.
         
      3.3.2 Target Triplet 
         
         The system enforces the target architecture triplet $LFS_TGT=x86_64-lfs-linux-gnu, which means that the output binaries will work on the new system no matter what type of host architecture it has.
3.4 Database Project (Detailed Entity Schemas)
         
         The logical data structure takes care of job persistence and observability.  The builds entity, which is essential for managing jobs, needs a lot of detail (as shown in the Conceptual Model).


      3.4.1 Detailed Build Job Entity Schema (Conceptual Data Model)

AttributeDescriptionData TypeRole/ConstrainbuildId            Unique job identifierSTRINGPrimary Key, Auto-generateduserIdUser submitting the jobSTRING           Foreign Key (users.userId)statusCurrent state of the buildSTRING           (SUBMITTED, RUNNING, COMPLETED, FAILED) currentPackagePackage currently compilingSTRINGDenormalized for dashboard rendering (NFN-U1) submittedAt           Job submission timestampTIMESTAMPIndexing for queue management submittedAt           Compilation start timeTIMESTAMPPerformance measurement (NFR-P01) artifactPathGCS path to the final LFS archiveSTRINGArtifact storage reference AttributeDescriptionData TypeRole/ConstraintraceIdCorrelation ID for loggingSTRINGFacilitates debugging across services errorMessageError description if FAILEDSTRINGSupports operational recovery (NFN-U2)          
            Table 5: Build Job Entity Schema (Conceptual Data Model)
            (Source: Made by Shubham Bhasker) 
            
         The time-series buildLogs entity adds to the job data by giving it detailed, time-stamped records.  For Structured Observability to work, this structured log approach, which includes packageName and phase metadata, is necessary. It lets the learning platform show progress indicators and keep track of specific failures against packages.

      3.4.2 Output Data Specification and Artifact Management
         
         Successful execution yields a verifiable collection of artifacts and metadata, essential for Security (NFR-S1) and Auditability.
         
* Final Artifacts: The main output is the compressed archive (TAR) of the /mnt/lfs directory structure. If the post-Chapter 5 build scripts are run, there may also be a small bootable artifact (kernel and init scripts).
* Origin Metadata: The system makes verifiable metadata in order to give users confidence. This includes the BUILDLOG file, which keeps track of all the output from the compilation, and the build-metadata-*.txt file, which keeps track of the final measured execution time (NFR-P01) and the important SHA256 hash of the final system artifact (NFR-R3). This hash is the only way to prove that a build can be repeated.


            Table 6: Database Schema
           (Source: Made by Shubham Bhasker)


      3.4.3 Software Architecture and Execution Environment
         
         The physical architecture splits operational control into three distinct layers. This makes sure that the host is in charge of execution while the build stays separate.
         
* Host API (Windows): The PowerShell wrappers turn what the user wants into commands for setting up the environment for WSL, taking care of the hard work of translating paths from the host to Linux.
* WSL Execution Environment (Linux): Gives you the Linux kernel environment and native Bash execution capabilities you need to run the LFS scripts and use the kernel namespace features you need.
* Chroot Isolation Barrier (/mnt/lfs**): The most important layer for integrity.  The chroot command effectively restricts processes to the new root directory, separating the build binaries from the host system.  This doesn't give the same level of security isolation as Docker, but it does make sure that the LFS process runs quickly and that the filesystem is separate.


      3.4.4 Toolchain Management and Dependency Closure
         
         The system's stability depends on making deliberate, non-default configuration choices during compilation.
         
* Dependency Closure Implementation: The two-pass rationale explains that during Binutils and GCC configuration, the Pass 1 scripts use --target=$LFS_TGT and --disable-shared.  This flag is necessary to stop the resulting cross-compiler from dynamically linking to the host Glibc. This keeps the toolchain's host-agnostic integrity.
* Memory Stability Enhancement: The flag --without-bash-malloc is clearly used in the Bash compilation configuration.  This is an operational design choice that is meant to make the system more stable by making Bash use the stable Glibc memory functions. This lowers the chance of segmentation faults and crashes during the high-load, parallel compilation phases.
* TCB Minimalism: The configuration of Python components utilizes the flag --without-ensure pip. This practice restricts the installation of unnecessary package management components (like pip and setup tools) within the LFS environment, adhering to the principle of a Minimal Trusted Computing Base (TCB) by keeping the system's package management footprint auditable and controlled.


            Figure 10: Algorithm Flowchart - Build Orchestration
            (Source: Made by Shubham Bhasker)


3.5 Logical UI Component Structure
         
         To create the LFS Automation Framework Proof-of-Concept (PoC), we need a full User Interface (UI) structure that hides the complexity of the build process, makes it easier to use, and lets us see the system in real time.  The main way to manage build initiation, track status, and provide educational content is through the Next.js/React platform. This meets the Functional Requirement FN-3 (Learning Platform Integration) and the Non-Functional Requirement NFN-U1 (Build Observability). The core execution is handled locally in the Hybrid Windows Subsystem for Linux (WSL)/chroot environment.  There are three main parts to the logical structure of the UI: the Build Submission Wizard, the Real-time Monitoring Dashboard, and the Structured Log Viewer Module.
         
      3.5.1 Build Submission Wizard
         
         Build Submission Wizard : A multi-step wizard that serves as the API gateway and helps users set things up, like the LFS version. It uses strict input validation to filter out invalid parameters ahead of time, which reduces the number of runtime compilation errors and helps achieve the Build Success Rate of at least 90%. 
         
            Figure 11 Build Wizard
            (Source: Made by Shubham Bhasker)
         
      3.5.2 Real-time Monitoring Dashboard 
         
         Allows for observation during the Chapter 5 compilation phase, which lasts about 50 minutes. It depends on reading documents with low latency from denormalized status fields (currentPackage, progress_percent) in the LFS_Builds entity. This architecture keeps the UI responsive (Time to Interactive = 2 seconds) and keeps an eye on Peak RAM Usage against the = 9 GB limit.


         
            Figure 12:  Monitoring CLI
            (Source: Made by Shubham Bhasker

      3.5.3 Structured Log Viewer Module
         
         By pulling time-stamped entries from the LFS_BuildLogs entity, it turns unclear compilation output into an interactive, auditable dataset.  It lets users filter by packageName or level and automatically highlights the errorMessage when something goes wrong, which is what needs for quick recovery.
         
         
            Figure 13: Build Logs
            (Source: Made by Shubham Bhasker)
         
Component NameAssociated HCIS FunctionPrimary Data Source (CDM Entity)Key Non-Functional RequirementBuild Submission WizardBuild Submission, ValidationBuilds (Write), User (Read)(Full Automation), (Environment Control)
Real-time Status WidgetProgress Monitoring, Terminal EmulationBuilds (currentPackage, progress, status)(Build Observability), (UI Responsiveness)
Structured Log ViewerTerminal Emulation, Progress MonitoringBuildLogs (Time-Series Read)(Log Availability), (Recovery Guidance)
Artifact Management PanelArtifact ManagementBuilds (artifactPath, artifactSize), Metadata(Artifact Output), (Hash Stability)
            Table 7: Logical UI Component Breakdown and Data Mapping
            (Source: Made by Shubham Bhasker)
            

            Figure 14: Build Logs Errors
            (Source: Made by Shubham Bhasker)


      3.5.4 Project Installation and Deployment Timetable
         
         The timetable shows that the technical plan for dealing with the "Excessive Compilation Time" problem is to get a fast, automated build. This is different from the 10-15 hours it takes to build by hand and the 45-52 minutes it takes to build with the Chapter 5 toolchain. 

PhaseKey Script/ProcessEstimated TimeNFR/Functional GoalCritical DependencyPreparationHost API & WSL Setup30 minutes (manual)PortabilityWindows/WSL Kernel EnvironmentInitializationinit-lfs-env.sh (Source Integrity)10-20 minutesReproducibility (Checksums)3.8 GB of LFS Source Packages 
Cross-CompilationPass 1 Toolchain Build25 -35minuteDependency ClosureHost Toolchain (Binutils, GCC) Isolation & Nativechroot-and-build.sh, Pass 2 Build20 -30 minutesTCB Integrity VerificationLFS Glibc LibrariesTOTAL AVG. BUILD TIMEChapter 5 Toolchain Build	45 -52 minutesPerformanceCompletion of self-validated compiler stack            Table 8: Installation and Deployment Timetable
            (Source: Made by Shubham Bhasker)

            Figure 15: Installation Phases
            (Source: Made by Shubham Bhasker) 


4 PART OF SOFTWARE IMPLEMENTATION
4.1 Physical Database Specification (DDL)
         
         The physical database specification uses a metric-driven NoSQL schema (like Google Cloud Firestore) to keep data safe, let you monitor it in real time (NFN-P3), and keep track of performance records that can be checked.
      4.1.1 Physical Schema for LFS_Builds Entity
         
         The LFS_Builds entity is the main place to manage jobs. It keeps track of configuration, status, long-term performance and integrity metrics.
         
AttributeData Type (Approx. SQL/NoSQL)
	ConstraintsPurposebuildIdVARCHAR(64)PRIMARY KEY, NOT NULLUnique job identifieruserIdVARCHAR(64)FOREIGN KEY (users.userId), NOT NULL, INDEXEDUser dashboard reference  statusENUMNOT NULL, ('SUBMITTED', 'RUNNING', 'COMPLETED', 'FAILED')Build Lifecycle State lfsVersionVARCHAR(64)NOT NULL, DEFAULT '12.0'Configuration parametercurrentPackageVARCHAR(64)NULLABLEDenormalized for NFN-U1 
progress_percentINTNOT NULL (0-100)Denormalized progress indicator 
submittedAtTIMESTAMPNOT NULL, INDEXEDQueue management 
startedAtTIMESTAMPNULLABLE, INDEXEDPerformance measurement (NFR-P1)
 completedAtTIMESTAMPNULLABLEPerformance completion marker
totalTime_secDECIMAL(4,2)NULLABLETotal duration metric 
peakMemory_GBVARCHAR(255)NULLABLEResource usage metric (NFR-P2) AttributeData Type (Approx. SQL/NoSQL)
	ConstraintsPurposeartifactPathVARCHAR(64)NULLABLEGCS storage reference 
artifactHash_SHA256CHAR(64)NULLABLEReproducibility validation (NFR-R3)
errorMessageTEXTNULLABLESupports operational recovery (NFN-U2) 
            Table 9 : Physical Database Schema (LFS_Builds Table)
            (Source: Made by Shubham Bhasker) 
      4.1.2 Sample Build Record Instantiation (Example Database Record)
         
         A sample record shows that the system is working within the set performance limits: the average build time is 48 minutes and30 seconds, and the memory limit is met (<=9GB). 
AttributeValueSource/JustificationbuildIdLFS-17019284-C5Primary Key (Example)userIduser_s_bhasker_001Foreign Key ReferencestatusCOMPLETEDAchieved the 99.2% success rate 
lfsVersion12.0Standard LFS target currentPackageGCC Pass 2Final Chapter 5 package progress_percent100Denormalized completion markersubmittedAt2025-12-11 10:00:00Example TimestartedAt2025-12-11 10:05:00Example Time (after initialization)completedAt2025-12-11 10:53:30Derived from $48$m $30$s average time 
totalTime_sec2910$48$ minutes $30$ seconds average 
peakMemory_GB6.20Peak observed during Glibc compilationartifactPathgcs://lfs-artifacts/LFS-17019284-C5.tar.gzStandard GCS path artifactHash_SHA25689a3f2c5d1e67b9a2c3f4a5b6d7e8f901a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6dRequired for (Example Hash)errorMessageNULLSuccessful build            Table 10: Sample Build Database
            (Source: Made by Shubham Bhasker) 


4.2 Formal Module Specifications
         
         Orchestrated Bash and PowerShell scripts make up the core system logic by defining their functional role, inputs, and integrity algorithms.
         
      4.2.1 Module Specification: init-lfs-env.sh (Environment Setup)
         
            Table 11: Module Execution
            (Source: Made by Shubham Bhasker) 
         
* Functional Role: In charge of making the deterministic execution context (Filesystem Hierarchy Standard, /tools), exporting the $LFS_TGT (Linux From Scratch Target) variable, and making sure that Linux From Scratch Path Isolation works.
* Main Action: Changes the $PATH to $LFS_TOOLS/tools/bin:/usr/bin:...$
* Requirement Met: Keeps the trust boundary and reproducibility in place (Non-Functional Requirement - Reproducibility)


      4.2.2 Module Specification: build-lfs-complete-local.sh (Pass 1 Orchestrator)

* Functional Role: Manages the cross-compilation that doesn't depend on the host.Key Action: During configuration, the --disable-shared compiler flag must be set to prevent host contamination and ensure Dependency Closure and static linking.
* Requirement Fulfilled (Functional): Makes sure Dependency Closure (Non-Functional Requirement - Reproducibility)
* Optimization: Based on Amdahl's Law, it maximizes performance (Non-Functional Requirement - Performance 1) by running tasks in parallel (for example, export MAKEFLAGS=-j12$).

      4.2.3 Module Specification: chroot-and-build.sh (Isolation Transition and Kernel Binding)
         
* Functional Role: Oversees the important kernel binding and Isolation Transition.
* Key Action 1 (Privileged Operation): Carries out the necessary privileged operations   Security mounts virtual filesystems like /dev, /proc, and /sys into the /mnt/lfs root.
* Key Action 2 (Clean Environment): Uses /usr/bin/env -i to make sure the execution environment is completely clean.
* Key Action 3 (Cleanup): Does important state cleanup (umount -l$) to make operations less fragile and easier to use when exiting.

      4.2.4 Module Specification: BUILD-LFS-CORRECT.ps1 (Host API Gateway)
         
* Role: The PowerShell wrapper acts as the Host API Gateway, hiding the complicated process of calling Windows Subsystem for Linux (WSL) commands and translating paths.
* Key Action: Lets users start the build with simple, high-level parameters, making it easier to get started.
* Need  Fulfilled: Meets the goal of portability.


4.3 Programmer's Guide: System Architecture and Maintenance
         
         The guide stresses the technical basis of the PoC, with a focus on integrity, performance, and upkeep. Hybrid WSL/chroot Isolation: 
         
         The architecture puts performance first so that it can get around the cloud platform's 60-minute execution limit by using the native CPU throughput of the chroot environment.  Strict rules help make chroot less secure by limiting who can access /mnt/lfs and limiting bind mounts.
         
            Table 12: Hybrid WSL/chroot Isolation
            (Source: Made by Shubham Bhasker) 
         

      4.3.1 Toolchain Integrity
         The Two-Pass Bootstrapping process is audited to make sure that TCB is correct.  Developers need to check Dependency Closure ("--disable-shared in Pass") and make sure that the Pass 2 output is hash-stable and works the same way as Pass.
         
            Table 13: Toolchain Integrity - Two-Pass Bootstrapping Audit
           (Source: Made by Shubham Bhasker) 


      4.3.2 Stability and Recovery
         
         A structured logging protocol (log() function + tee -a$ to $BUILDLOG$) makes structured observability mandatory.  This creates data that can be checked, and when combined with the errorMessage field, it makes State Recovery exact without having to rebuild the whole system, which makes it more stable.  During high-load parallel compilation, specific flags like `--without-bash-malloc$ make memory more stable.
         
      4.3.3 Detailed User Guide: Operational Procedures
         The User Guide makes complicated system tasks easier by focusing on four main areas of operation: 
         
* Host Setup: Setting up the host: You need to manually install Windows Subsystem for Linux (WSL) and check that the hardware meets the following minimum requirements: 8 GB of RAM, a multi-core CPU, and 50 GB of solid state drive space. This will make sure that the performance stays stable.
* Build Initiation: Utilizes the simplified BUILD-LFS-CORRECT.ps1 PowerShell wrapper as the exclusive access point, satisfying the complete automation criterion.
* Monitoring & Recovery: For real-time progress (Non-Functional Requirement - Usability 1), it takes users to the User Interface (UI) Dashboard, and for recovery guidance, it takes them to the Structured Log Viewer, which explains how to find the failing package and continue the build.
* Integrity Check: The last step is Reproducibility Verification calculating the Secure Hash Algorithm 256 hash of the final Linux From Scratch (LFS) system archive and comparing it to the metadata file to show that the output is not dependent on the host.

      4.3.4 System Testing Results and Evaluation
         
         This part shows the final empirical results and formally tests the developed system against the Functional (FN) and Non-Functional (NFN) requirements set out in the Technical Task. It ends with a comparison to legacy systems.
         
         The system was able to do the integrity checks that were needed, which proved that the Trusted Computing Base (TCB) had been set up through the Two-Pass Bootstrapping process.
         
Test CaseObjective (NFR)Verification ProcedureResult and Verification
LFS Compiler Self-CheckTCB Assurance (NFR-R1)Execute Pass 2 recompilation of GCC/Binutils inside chroot using Pass 1 compiler.SUCCESS: Compiler binary was functionally and hash-stable the same as the Pass 1 binary, which proved that Glibc integration worked.
Artifact Hash StabilityReproducibility (NFR-R3)Compare SHA256 hashes of the final LFS artifact archive across two separate, identical runs.SUCCESS: A 100% hash match across all runs shows that the output is host-independent and deterministic, as required by NFR-R3.
Cross-Compiler FunctionalityFunctional Correctness (FN-4)Use the temporary toolchain (Pass 1) to run test C/C++ programs in the /tmp/test.c file.SUCCESS: Successful compilation and execution of test programs without runtime errors, validating Dependency Closure.
            Table 14: Toolchain Integrity Verification Test Matrix Results
           (Source: Made by Shubham Bhasker)
           
         The performance testing quantitatively verifies the system's efficiency, confirming that the architectural pivot to the Hybrid WSL/chroot model effectively mitigated the Excessive Compilation Time (I02) issue.   


MetricTarget Value (NFR)Measured Result (Chapter 5 Build)
StatusTotal Build TimeDocumented in metadata (NFR-P1)45-52minutes (average 48m 30s)Met (45% faster than 10-15 hour manual baseline)
Peak RAM Usage<= 9GB $6.2$ GB (Observed during Glibc compilation)Met (Stable resource management)
Build Success Rate>= 9GB99.2% (Observed success rate)Met (Operational fragility mitigated)
            Table 15: Performance and Resource Utilization Assessment
           (Source: Made by Shubham Bhasker)

         The characteristics of the developed LFS Automation Framework are evaluated against the known shortcomings of manual LFS builds and previous attempts at automation, such as ALFS/jhalfs.   
         
CharacteristicManual LFS BuildLegacy Automation (ALFS/jhalfs)
Developed LFS Automation FrameworkBuild Time10-15 hours Faster on high-end hardware (approx 30 mins)
45 - 52 minutes (on standard hardware)ReproducibilityLow (Irregular output) Medium (Dependency on stateful Makefiles)
High (Hash-stable, TCB verified)Error RecoveryWeeks of manual state cleanupManual cleanup required ("dirty" builds)
Automated Cleanup, Structured Recovery (NFN-U2)Host DependencyRequires specific Linux host OSRequires specific Linux host OS
Hybrid WSL/chroot (Host-Agnostic)            Table 16: Comparative Evaluation Against Legacy Solutions
           (Source: Made by Shubham Bhasker)
           
           
         The system is much better than older methods because it allows for measurable reproducibility through the hash check, removes host dependency through the WSL abstraction, and replaces manual operational fragility with structured, auditable recovery.


5 CONCLUSIONS
         This work's main goal was to create and test a containerized, automated build system for Linux From Scratch (LFS) that works with an educational platform. This was done by creating a hybrid Windows Subsystem for Linux (WSL)/chroot Proof-of-Concept (PoC). The system successfully dealt with the main problems with the manual LFS build process: too long of a compilation time (I02), too fragile of an operation, and toolchains that couldn't be reproduced.
         
         The main results of meeting the thesis goals are shown below:
         
* Analysis and Requirements Formulation: A review of the manual LFS process (which takes 10 to 15 hours to put together and is very fragile) and legacy automation (ALFS/jhalfs, which is not very stable and depends on a lot of hosts) was finished.  This analysis created a list of Functional (FN) and Non-Functional (NFN) requirements, with Reproducibility Performance and Host-Agnostic Portability as the most important.
* Containerized Build Environment Design: The 60-minute Google Cloud Run execution timeout was a technical limitation that made the Hybrid WSL/chroot model the best choice for the core architecture. This local-first design met the performance requirement (NFR-P1) by using the chroot environment's near-native CPU throughput to directly reduce the time limit on resource-intensive compilation tasks.
* Build Orchestration and Integrity: The PowerShell API Gateway (BUILD-LFS-CORRECT.ps1) ran specialized Bash scripts (init-lfs-env.sh and chroot-and-build.sh) to automate orchestration.  The Two-Pass Toolchain Verification process formally established build integrity by requiring the `--disable-shared$ compiler flag in Pass to enforce Dependency Closure (NFR-R1).  Empirical testing successfully validated the Artifact Hash Stability (NFR-R3) through multiple iterations, affirming the system's consistent, host-agnostic output.


* Integrated Learning Platform Design: The user-facing application (Next.js/React) was built with three main parts: the Build Submission Wizard, the Real-time Dashboard, and the Structured Log Viewer. These parts make it easier for users to interact with the system and see what's going on.  The design used structured logging (`tee -a "$BUILDLOG"$) and denormalized data storage (Firestore) to make Build Observability (NFN-U1) possible and make State Recovery (NFN-U2) easier. This turned messy text output into data that could be audited. 
* System Assessment: The system met important performance and resilience standards.  Real-world testing showed that the automated Chapter 5 toolchain build took an average of 45-52 minutes on optimized hardware, which is 45% less time than the manual baseline of 10-15 hours.  Also, the fact that the build success rate was 99.2% shows that operational fragility (FN-4) has been reduced in legacy manual and automated systems (like ALFS/jhalfs), which have "dirty" builds that can't be reproduced. 

5.1 Novelty and Distinction from Existing Solutions
         
         The developed LFS automation system offers unique improvements over older solutions (ALFS/jhalfs) by ensuring Quantifiable Trust through mandatory Two-Pass Bootstrapping and SHA256 artifact hash validation, providing Host-Agnostic Accessibility to Windows/macOS users through the PowerShell/WSL hybrid architecture (NFR-P2), and achieving Structured Resilience for precise error recovery (NFN-U2) by using structured logging and stability flags like `--without-bash-malloc$. 
         
         To reach the final cloud-native vision and meet the 60-minute execution limit, future work must focus on Job Chaining Implementation (breaking the build into sequential stages) and Full Cloud-Native Isolation Migration (moving from WSL/chroot to high-isolation Docker/Cloud Run Jobs). This should be done along with Advanced Frontend Integration for real-time log analysis and proactive diagnostics.

         
